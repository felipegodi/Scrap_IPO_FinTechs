name: Daily Scraper

on:
  schedule:
    - cron: '0 11 * * *'  # Schedule to run every day at 8 am Buenos Aires time (which is 11 am UTC)

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          pip install requests
          pip install beautifulsoup4
          pip install pandas
          pip install openpyxl

      - name: Create directory
        run: mkdir -p metrics  # This directory is within your repository

      - name: Run scraper
        run: python IPO_scraper.py  # Replace with the actual name of your Python script

      - name: Upload Excel file
        uses: actions/upload-artifact@v2
        with:
          name: scraped-data  # Give your artifact a name
          path: metrics/stocks*.xlsx  # Specify the path to the Excel file(s) within your repository

      - name: Commit and push changes
        run: |
          git config user.name "felipegodi"
          git config user.email "felipegarciavassallo@gmail.com"
          git add .
          git commit -m "Auto-generated data update"
          git push https://${{ secrets.GH_PAT }}@github.com/felipegodi/Scrap_IPO_FinTechs.git
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
